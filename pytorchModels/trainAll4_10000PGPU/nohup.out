Initializing model ...
Loading the training dataset ...
The size of training dataset: 11024009
Start training ...
Learning rate: 1.00e-03
L2 regularization lambda: 1.00e-03
/usr/local/lib/python2.7/dist-packages/torch/nn/parallel/data_parallel.py:24: UserWarning: 
    There is an imbalance between your GPUs. You may want to exclude GPU 1 which
    has less than 75% of the memory or cores of GPU 0. You can do so by setting
    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES
    environment variable.
  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))
1 Training loss: 0.8408876329139704 Validation loss:  0.48392789103036693
Epoch time elapsed: 347.99 s
2 Training loss: 0.4227758436562857 Validation loss:  0.3785567947765826
Epoch time elapsed: 345.09 s
3 Training loss: 0.34158333222103304 Validation loss:  0.31957822258785606
Epoch time elapsed: 345.12 s
4 Training loss: 0.2926155793002269 Validation loss:  0.2758724671740663
Epoch time elapsed: 345.13 s
5 Training loss: 0.2637487685554442 Validation loss:  0.2572935469147948
Epoch time elapsed: 346.20 s
6 Training loss: 0.24524846130819974 Validation loss:  0.23732619189061172
Epoch time elapsed: 346.77 s
7 Training loss: 0.23188164647364165 Validation loss:  0.22747006249488352
Epoch time elapsed: 346.49 s
8 Training loss: 0.2217880656994554 Validation loss:  0.21989541723686223
Epoch time elapsed: 346.29 s
9 Training loss: 0.213693650571222 Validation loss:  0.21095477832440715
Epoch time elapsed: 346.62 s
10 Training loss: 0.20434453107082196 Validation loss:  0.20304360715274974
Epoch time elapsed: 345.86 s
11 Training loss: 0.19833106097920475 Validation loss:  0.19871209052157507
Epoch time elapsed: 346.20 s
12 Training loss: 0.19354580872022348 Validation loss:  0.19510530446703359
Epoch time elapsed: 346.25 s
13 Training loss: 0.18948916310069933 Validation loss:  0.19206513427749428
Epoch time elapsed: 345.67 s
14 Training loss: 0.18596344902998743 Validation loss:  0.19043386566524323
Epoch time elapsed: 345.29 s
15 Training loss: 0.1830586475712318 Validation loss:  0.18694076217483885
Epoch time elapsed: 345.65 s
16 Training loss: 0.1802154858494641 Validation loss:  0.18534958384379593
Epoch time elapsed: 345.44 s
17 Training loss: 0.17804246166174784 Validation loss:  0.18502101967184223
Epoch time elapsed: 345.36 s
18 Training loss: 0.17552791003787674 Validation loss:  0.18139116783446602
Epoch time elapsed: 344.15 s
19 Training loss: 0.1739811602451831 Validation loss:  0.1812126623390375
Epoch time elapsed: 344.95 s
20 Training loss: 0.17192484701068617 Validation loss:  0.17906118361801127
Epoch time elapsed: 349.66 s
21 Training loss: 0.17045763591105503 Validation loss:  0.1784291002967534
Epoch time elapsed: 505.08 s
22 Training loss: 0.16918682622114012 Validation loss:  0.17820752833876624
Epoch time elapsed: 498.39 s
23 Training loss: 0.16779966525796053 Validation loss:  0.1757874050929991
Epoch time elapsed: 502.16 s
24 Training loss: 0.16659385809237728 Validation loss:  0.1761910456134593
Epoch time elapsed: 477.33 s
25 Training loss: 0.16533639158879443 Validation loss:  0.17493059865038177
Epoch time elapsed: 503.92 s
26 Training loss: 0.16478234622900764 Validation loss:  0.17505305236251417
Epoch time elapsed: 497.72 s
27 Training loss: 0.16356411967163692 Validation loss:  0.17494096776949045
Epoch time elapsed: 499.69 s
New learning rate: 1.00e-04
New L2 regularization lambda: 1.00e-04
28 Training loss: 0.15252446986075352 Validation loss:  0.1656886854024904
Epoch time elapsed: 483.85 s
29 Training loss: 0.15001956795522003 Validation loss:  0.16515473424133956
Epoch time elapsed: 492.65 s
30 Training loss: 0.14903863715361287 Validation loss:  0.16470866718349764
Epoch time elapsed: 494.54 s
31 Training loss: 0.14829630738403635 Validation loss:  0.16386755286836227
Epoch time elapsed: 492.84 s
32 Training loss: 0.14766901574953328 Validation loss:  0.1641336988452254
Epoch time elapsed: 486.39 s
33 Training loss: 0.14728050638963494 Validation loss:  0.16455338150835955
Epoch time elapsed: 497.15 s
34 Training loss: 0.14685445727691487 Validation loss:  0.16369414523341227
Epoch time elapsed: 493.42 s
35 Training loss: 0.14647916840073563 Validation loss:  0.16387868477661482
Epoch time elapsed: 500.67 s
36 Training loss: 0.14605835112171886 Validation loss:  0.16431154345328472
Epoch time elapsed: 486.65 s
37 Training loss: 0.14574602771948295 Validation loss:  0.16461890700171838
Epoch time elapsed: 495.39 s
38 Training loss: 0.1454503483428976 Validation loss:  0.1634629167171928
Epoch time elapsed: 505.03 s
39 Training loss: 0.14512634511109884 Validation loss:  0.16358070160052773
Epoch time elapsed: 518.49 s
40 Training loss: 0.14493602088263755 Validation loss:  0.1638423056582581
Epoch time elapsed: 520.39 s
41 Training loss: 0.1447278888299832 Validation loss:  0.16288736987507568
Epoch time elapsed: 499.39 s
42 Training loss: 0.14448593779392524 Validation loss:  0.16408031598436382
Epoch time elapsed: 494.86 s
43 Training loss: 0.14404623304798084 Validation loss:  0.16343669490388585
Epoch time elapsed: 499.11 s
44 Training loss: 0.14383256841534106 Validation loss:  0.16342984329114285
Epoch time elapsed: 485.58 s
45 Training loss: 0.14377117979239415 Validation loss:  0.1631985971184531
Epoch time elapsed: 501.10 s
46 Training loss: 0.1436109117000144 Validation loss:  0.16327181276858546
Epoch time elapsed: 500.57 s
47 Training loss: 0.1431332063005579 Validation loss:  0.16305243189442573
Epoch time elapsed: 503.06 s
48 Training loss: 0.1432199509946222 Validation loss:  0.16379262928790123
Epoch time elapsed: 492.45 s
49 Training loss: 0.14292990413919596 Validation loss:  0.16298672493141692
Epoch time elapsed: 502.47 s
New learning rate: 1.00e-05
New L2 regularization lambda: 1.00e-05
50 Training loss: 0.14168748243023585 Validation loss:  0.16209285196906337
Epoch time elapsed: 496.77 s
51 Training loss: 0.14137403807017723 Validation loss:  0.16236220943856394
Epoch time elapsed: 499.44 s
52 Training loss: 0.14113702282147003 Validation loss:  0.16228941796187998
Epoch time elapsed: 510.67 s
53 Training loss: 0.1411809794546487 Validation loss:  0.16246125575928194
Epoch time elapsed: 482.77 s
54 Training loss: 0.14109599131621986 Validation loss:  0.16198093157093998
Epoch time elapsed: 493.18 s
55 Training loss: 0.14105986367078804 Validation loss:  0.16211632891451327
Epoch time elapsed: 430.92 s
Training time elapsed: 24265.48 s
Best validation loss at batch: 54
Testing on the training and validation dataset ...
Prediciton time elapsed: 492.26 s
Version 2 model, evaluation on base change:
all/top1/top2/top1p/top2p: 11024009/9679994/10912024/87.81/98.98
Version 2 model, evaluation on Zygosity:
2088410	103441
132293	8699865
Version 2 model, evaluation on variant type:
7345933	25012	10178	12266
27839	3160935	2412	1149
13623	5232	167403	22898
14582	1281	16544	196722
Version 2 model, evaluation on indel length:
10562214	16059	2556	938	1548	2409
21930	223917	1653	164	140	529
5626	25432	37602	1819	1298	1277
3478	5637	3596	11311	4668	924
3446	1825	5355	3362	20856	5390
3633	1271	2767	510	6357	32512
