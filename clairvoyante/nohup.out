Initializing model ...
("Let's use", 2L, 'GPUs!')
Traceback (most recent call last):
  File "train.py", line 280, in <module>
    Run(args)
  File "train.py", line 39, in Run
    m.to(device)
  File "/usr/local/lib/python2.7/dist-packages/torch/nn/modules/module.py", line 379, in to
    return self._apply(convert)
  File "/usr/local/lib/python2.7/dist-packages/torch/nn/modules/module.py", line 185, in _apply
    module._apply(fn)
  File "/usr/local/lib/python2.7/dist-packages/torch/nn/modules/module.py", line 191, in _apply
    param.data = fn(param.data)
  File "/usr/local/lib/python2.7/dist-packages/torch/nn/modules/module.py", line 377, in convert
    return t.to(device, dtype if t.is_floating_point() else None, non_blocking)
RuntimeError: CUDA error: out of memory
